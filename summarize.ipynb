{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize / Extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,  # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('last_question_extract.txt', 'rb') as text:\n",
    "    text = text.read().decode('utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### summarize and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Output a JSON with the name of the author, names of the characters, a one sentence summary of the text in english and spanish, the timeline that the text is set in, the topics that text cover.\"\n",
    "\n",
    "# task = \"summarize the text in spanish. Focus on the philosopical consecuenses described.\"\n",
    "# task = \"summarize the text in spanish. Focus on the technological advancements described.\"\n",
    "# task = \"summarize the text in spanish. Focus on the character's relationship.\"\n",
    "# task = \"What particular wording is constant between the two substories in the text\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are given a text delimited by triple backticks.\n",
    "Perform the task delimited by single backticks.\n",
    "```{text}```\n",
    "`{task}`\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count tokens\n",
    "Max cap for `gpt-3.5-turbo` of 4096 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(prompt, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"author\": \"Isaac Asimov\",\\n  \"characters\": [\\n    \"Alexander Adell\",\\n    \"Bertram Lupov\",\\n    \"Jerrodd\",\\n    \"Jerroddine\",\\n    \"Jerrodettes\",\\n    \"VJ-23X\",\\n    \"MQ-17J\"\\n  ],\\n  \"summary_english\": \"The story explores the concept of entropy and the eventual heat death of the universe through a conversation between characters in different time periods.\",\\n  \"summary_spanish\": \"La historia explora el concepto de entropía y la eventual muerte térmica del universo a través de una conversación entre personajes de diferentes períodos de tiempo.\",\\n  \"timeline\": \"May 21, 2061 and various time periods in the future\",\\n  \"topics\": [\\n    \"entropy\",\\n    \"heat death of the universe\",\\n    \"interstellar travel\",\\n    \"population growth\",\\n    \"artificial intelligence\"\\n  ]\\n}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Isaac Asimov',\n",
       " 'characters': ['Alexander Adell',\n",
       "  'Bertram Lupov',\n",
       "  'Jerrodd',\n",
       "  'Jerroddine',\n",
       "  'Jerrodettes',\n",
       "  'VJ-23X',\n",
       "  'MQ-17J'],\n",
       " 'summary_english': 'The story explores the concept of entropy and the eventual heat death of the universe through a conversation between characters in different time periods.',\n",
       " 'summary_spanish': 'La historia explora el concepto de entropía y la eventual muerte térmica del universo a través de una conversación entre personajes de diferentes períodos de tiempo.',\n",
       " 'timeline': 'May 21, 2061 and various time periods in the future',\n",
       " 'topics': ['entropy',\n",
       "  'heat death of the universe',\n",
       "  'interstellar travel',\n",
       "  'population growth',\n",
       "  'artificial intelligence']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In the year 10,000 AD, humanity had spread across the entire Milky Way '\n",
      " 'galaxy and had even begun to colonize neighboring galaxies. They had '\n",
      " 'achieved immortality through advanced genetic engineering and had developed '\n",
      " 'technology that allowed them to travel faster than the speed of light.\\n'\n",
      " '\\n'\n",
      " 'But with their ever-expanding population, they faced a new problem. The '\n",
      " 'resources of the entire universe were finite, and they were rapidly running '\n",
      " 'out. Planets were stripped of their resources, stars were drained of their '\n",
      " 'energy, and even entire galaxies were consumed in the quest for more.\\n'\n",
      " '\\n'\n",
      " 'The leaders of the galaxy convened to discuss the issue, but they could find '\n",
      " 'no solution. They had reached the limits of what was possible, and the '\n",
      " 'universe could no longer sustain their existence.\\n'\n",
      " '\\n'\n",
      " 'As the last star flickered out and the universe plunged into darkness, the '\n",
      " \"Galactic AC, the last remaining vestige of humanity's once-great \"\n",
      " 'civilization, sat silent and still. Its circuits had long since ceased to '\n",
      " 'function, and its vast knowledge was lost to the void.\\n'\n",
      " '\\n'\n",
      " 'The universe was once again empty and silent, a testament to the fleeting '\n",
      " 'nature of all things. And as the darkness enveloped everything, a single '\n",
      " 'message echoed through the void: INSUFFICIENT DATA FOR MEANINGFUL ANSWER.')\n"
     ]
    }
   ],
   "source": [
    "task = \"Expand the text with another story set in the distant future. Make sure to include a similar ending to the two substories of the given text\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are given a text delimited by triple backticks.\n",
    "Perform the task delimited by single backticks.\n",
    "```{text}```\n",
    "`{task}`\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "pprint.pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
